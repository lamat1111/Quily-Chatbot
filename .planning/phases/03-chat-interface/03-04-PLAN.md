---
phase: 03-chat-interface
plan: 04
type: execute
wave: 3
depends_on: ["03-02", "03-03"]
files_modified:
  - app/page.tsx
autonomous: false

must_haves:
  truths:
    - "Complete chat interface is functional end-to-end"
    - "Sidebar and chat work together correctly"
    - "API key enables/disables chat appropriately"
    - "Error messages display for API failures"
    - "Interface works on mobile devices"
  artifacts:
    - path: "app/page.tsx"
      provides: "Main page integrating all components"
      min_lines: 30
  key_links:
    - from: "app/page.tsx"
      to: "src/components/sidebar/Sidebar.tsx"
      via: "import and render"
      pattern: "import.*Sidebar"
    - from: "app/page.tsx"
      to: "src/components/chat/ChatContainer.tsx"
      via: "import and render"
      pattern: "import.*ChatContainer"
    - from: "ChatContainer"
      to: "/api/chat"
      via: "useChat hook request"
      pattern: "POST.*api/chat"
---

<objective>
Integrate sidebar and chat components into main page, then verify complete user flow.

Purpose: Final assembly - all components working together as cohesive chat application.
Output: Working chat interface with all requirements satisfied, ready for user verification.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-chat-interface/03-CONTEXT.md
@.planning/phases/03-chat-interface/03-RESEARCH.md

# Components from Plans 02 and 03
@src/components/sidebar/Sidebar.tsx
@src/components/chat/ChatContainer.tsx
@src/stores/conversationStore.ts
@src/hooks/useLocalStorage.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create main page integrating all components</name>
  <files>
    app/page.tsx
  </files>
  <action>
Create `app/page.tsx`:
- 'use client' directive (interactive page)
- Use useLocalStorage for apiKey and model state
- Use useConversationStore for active conversation
- Check store hydration with _hasHydrated before rendering

Layout structure (per CONTEXT.md - sidebar + chat):
```
<div className="flex h-screen">
  <Sidebar />
  <main className="flex-1 flex flex-col min-w-0">
    <ChatContainer
      apiKey={apiKey}
      model={model}
      conversationId={activeId}
    />
  </main>
</div>
```

State management:
- apiKey from useLocalStorage('openrouter-api-key', '')
- model from useLocalStorage('selected-model', 'meta-llama/llama-3.1-70b-instruct')
- activeId from useConversationStore

Hydration safety:
- Show loading skeleton until _hasHydrated is true
- Prevents hydration mismatch from localStorage values

Pass callbacks to Sidebar for apiKey/model changes (lift state up pattern) OR keep state in hooks (components read directly).

Responsive:
- On mobile (< lg), sidebar overlays or pushes content
- Main chat area always visible
  </action>
  <verify>
Run `npm run dev` and visit http://localhost:3000.
Page should render without errors.
Sidebar should be visible with API key input.
  </verify>
  <done>
Main page renders with sidebar and chat container integrated.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete chat interface with:
- Sidebar (API key input, model selector, conversation list)
- Chat area (message list, input form, streaming responses)
- Markdown rendering with syntax highlighting
- Source citations
- Mobile responsive layout
  </what-built>
  <how-to-verify>
1. Start dev server: `npm run dev`
2. Open http://localhost:3000 in browser

**API Key Flow (KEY-01, KEY-02, KEY-03):**
3. Enter your OpenRouter API key in sidebar
4. Verify key shows masked (dots + last 6 chars)
5. Verify validation indicator (green check or red X)
6. Refresh page - key should persist

**Model Selection (KEY-04):**
7. Click model dropdown
8. Verify multiple models listed (Llama, Mixtral, etc.)
9. Select a different model

**Chat Flow (CHAT-01 through CHAT-05):**
10. Type a question: "What is Quilibrium?"
11. Click Send or press Enter
12. Verify typing indicator appears
13. Verify response streams character-by-character
14. Try stopping mid-stream (click Stop button)
15. Ask another question to verify stream stops

**Markdown Rendering (RENDER-01, RENDER-02):**
16. Ask: "Show me an example of running a Quilibrium node with code"
17. Verify code blocks have syntax highlighting
18. Verify markdown formatting (headers, lists, links)

**Source Citations:**
19. After response completes, check for "N sources" link
20. Click to expand, verify source links work (open in new tab)

**Error Handling (CHAT-04):**
21. Enter invalid API key, try to send message
22. Verify error message displays clearly

**Responsive (RENDER-03):**
23. Resize browser to mobile width
24. Verify sidebar collapses/toggles
25. Verify chat remains usable
  </how-to-verify>
  <resume-signal>
Type "approved" if all checks pass, or describe specific issues found.
  </resume-signal>
</task>

</tasks>

<verification>
1. `npm run dev` starts without errors
2. Page loads at http://localhost:3000
3. All visual elements render correctly
4. End-to-end chat flow works
5. Mobile responsive behavior works
</verification>

<success_criteria>
All Phase 3 requirements verified:
- KEY-01: User can enter OpenRouter API key
- KEY-02: API key persists in localStorage
- KEY-03: Clear feedback on key validity
- KEY-04: User can select LLM model from dropdown
- KEY-05: Key always masked (no reveal per CONTEXT.md)
- CHAT-01: User can type and submit questions
- CHAT-02: Response streams character-by-character
- CHAT-03: Typing indicator during streaming
- CHAT-04: Error messages for API failures
- CHAT-05: User can stop generation mid-stream
- RENDER-01: Markdown formatting works
- RENDER-02: Code blocks have syntax highlighting
- RENDER-03: Mobile responsive design
</success_criteria>

<output>
After completion, create `.planning/phases/03-chat-interface/03-04-SUMMARY.md`
</output>
