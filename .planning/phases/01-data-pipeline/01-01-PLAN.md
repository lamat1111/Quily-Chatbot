---
phase: 01-data-pipeline
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - package.json
  - tsconfig.json
  - .env.example
  - scripts/db/schema.sql
  - scripts/ingest/types.ts
autonomous: true
user_setup:
  - service: supabase
    why: "Vector storage for document embeddings"
    env_vars:
      - name: SUPABASE_URL
        source: "Supabase Dashboard -> Project Settings -> API -> Project URL"
      - name: SUPABASE_SERVICE_KEY
        source: "Supabase Dashboard -> Project Settings -> API -> service_role key (NOT anon)"
    dashboard_config:
      - task: "Enable pgvector extension"
        location: "Supabase Dashboard -> Database -> Extensions -> Search 'vector' -> Enable"
  - service: openrouter
    why: "Embedding generation via text-embedding-3-small"
    env_vars:
      - name: OPENROUTER_API_KEY
        source: "OpenRouter Dashboard -> Keys -> Create Key"

must_haves:
  truths:
    - "npm install completes without errors"
    - "TypeScript compiles without errors"
    - "Database schema exists in Supabase with pgvector extension"
    - "Similarity search function is callable via RPC"
  artifacts:
    - path: "package.json"
      provides: "Project dependencies and scripts"
      contains: "@langchain/textsplitters"
    - path: "tsconfig.json"
      provides: "TypeScript configuration"
      contains: "strict"
    - path: "scripts/db/schema.sql"
      provides: "Database schema with pgvector"
      contains: "vector(1536)"
    - path: "scripts/ingest/types.ts"
      provides: "Shared TypeScript interfaces"
      exports: ["ChunkWithContext", "ChunkMetadata", "DocumentChunk"]
  key_links:
    - from: "scripts/db/schema.sql"
      to: "Supabase pgvector"
      via: "SQL execution"
      pattern: "CREATE TABLE document_chunks"
---

<objective>
Set up the project foundation with TypeScript configuration, dependencies, database schema, and shared type definitions.

Purpose: Establishes the foundation that all other plans build upon. Without this, no code can compile or run.
Output: Working TypeScript project with database schema ready for vector storage.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-data-pipeline/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Initialize TypeScript project with dependencies</name>
  <files>package.json, tsconfig.json, .env.example</files>
  <action>
Initialize npm project and install all required dependencies:

1. Run `npm init -y` to create package.json
2. Install production dependencies:
   ```bash
   npm install @langchain/textsplitters @langchain/core ai @openrouter/ai-sdk-provider @supabase/supabase-js gpt-tokenizer commander ora chalk dotenv glob
   ```
3. Install dev dependencies:
   ```bash
   npm install -D typescript @types/node tsx
   ```
4. Create tsconfig.json with:
   - target: ES2022
   - module: NodeNext
   - moduleResolution: NodeNext
   - strict: true
   - outDir: dist
   - rootDir: .
   - include: ["scripts/**/*"]
   - esModuleInterop: true
   - skipLibCheck: true

5. Add to package.json scripts:
   ```json
   "scripts": {
     "ingest": "tsx scripts/ingest/index.ts",
     "typecheck": "tsc --noEmit"
   }
   ```

6. Create .env.example with:
   ```
   SUPABASE_URL=your_supabase_project_url
   SUPABASE_SERVICE_KEY=your_supabase_service_role_key
   OPENROUTER_API_KEY=your_openrouter_api_key
   ```

7. Add .env to .gitignore (create if not exists)

Do NOT use ES modules in package.json (no "type": "module") - tsx handles this.
  </action>
  <verify>
Run `npm install` (should succeed with no errors)
Run `npx tsc --noEmit` (should succeed with no errors)
Check .env.example exists with 3 env vars
  </verify>
  <done>
package.json has all dependencies listed in research, tsconfig.json compiles TypeScript, .env.example documents required environment variables
  </done>
</task>

<task type="auto">
  <name>Task 2: Create database schema for vector storage</name>
  <files>scripts/db/schema.sql</files>
  <action>
Create the pgvector schema file with table and RPC function:

1. Create `scripts/db/` directory
2. Create `scripts/db/schema.sql` with:

```sql
-- Enable pgvector extension (run in Supabase SQL editor)
CREATE EXTENSION IF NOT EXISTS vector WITH SCHEMA extensions;

-- Document chunks table for RAG
CREATE TABLE IF NOT EXISTS document_chunks (
  id BIGINT PRIMARY KEY GENERATED ALWAYS AS IDENTITY,
  content TEXT NOT NULL,
  embedding vector(1536) NOT NULL,
  source_file TEXT NOT NULL,
  heading_path TEXT,
  chunk_index INTEGER NOT NULL,
  token_count INTEGER NOT NULL,
  version TEXT,
  content_hash TEXT NOT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW(),

  -- Unique constraint for upsert (prevents duplicates on re-ingestion)
  UNIQUE(source_file, chunk_index)
);

-- HNSW index for fast cosine similarity search
-- Parameters: m=16, ef_construction=64 (good defaults for <10k vectors)
CREATE INDEX IF NOT EXISTS document_chunks_embedding_idx
  ON document_chunks
  USING hnsw (embedding vector_cosine_ops)
  WITH (m = 16, ef_construction = 64);

-- Index for filtering by source file
CREATE INDEX IF NOT EXISTS document_chunks_source_idx
  ON document_chunks(source_file);

-- RPC function for similarity search (required because PostgREST doesn't support pgvector operators)
CREATE OR REPLACE FUNCTION match_document_chunks(
  query_embedding vector(1536),
  match_threshold FLOAT DEFAULT 0.7,
  match_count INT DEFAULT 5
)
RETURNS TABLE (
  id BIGINT,
  content TEXT,
  source_file TEXT,
  heading_path TEXT,
  similarity FLOAT
)
LANGUAGE plpgsql
AS $$
BEGIN
  RETURN QUERY
  SELECT
    dc.id,
    dc.content,
    dc.source_file,
    dc.heading_path,
    1 - (dc.embedding <=> query_embedding) AS similarity
  FROM document_chunks dc
  WHERE 1 - (dc.embedding <=> query_embedding) > match_threshold
  ORDER BY dc.embedding <=> query_embedding
  LIMIT match_count;
END;
$$;
```

Note: User must run this SQL in Supabase Dashboard -> SQL Editor. Claude cannot execute SQL directly against Supabase.
  </action>
  <verify>
File scripts/db/schema.sql exists
Contains CREATE TABLE document_chunks
Contains CREATE FUNCTION match_document_chunks
Contains vector(1536) type
  </verify>
  <done>
Schema file is ready for user to execute in Supabase SQL Editor. Contains table, HNSW index, and RPC function.
  </done>
</task>

<task type="auto">
  <name>Task 3: Define shared TypeScript interfaces</name>
  <files>scripts/ingest/types.ts</files>
  <action>
Create the shared types file that all ingest modules will import:

1. Create `scripts/ingest/` directory
2. Create `scripts/ingest/types.ts` with:

```typescript
/**
 * Metadata attached to each document chunk
 */
export interface ChunkMetadata {
  /** Original source file path, e.g., "docs/getting-started.md" */
  source_file: string;
  /** Heading hierarchy, e.g., "Installation > Prerequisites" */
  heading_path: string;
  /** Position of this chunk in the source document */
  chunk_index: number;
  /** Number of tokens in this chunk (for cost tracking) */
  token_count: number;
  /** Version tag for freshness tracking, e.g., "2026-01-24" */
  version: string;
  /** MD5 hash of content for deduplication */
  content_hash: string;
}

/**
 * A chunk of text with its metadata (before embedding)
 */
export interface ChunkWithContext {
  /** The actual text content of the chunk */
  content: string;
  /** Associated metadata */
  metadata: ChunkMetadata;
}

/**
 * A document chunk with its embedding vector (ready for upload)
 */
export interface DocumentChunk extends ChunkWithContext {
  /** 1536-dimensional embedding vector from text-embedding-3-small */
  embedding: number[];
}

/**
 * Raw loaded document before chunking
 */
export interface LoadedDocument {
  /** File path relative to docs root */
  path: string;
  /** Full markdown content */
  content: string;
  /** Frontmatter if present */
  frontmatter?: Record<string, unknown>;
}

/**
 * Result from similarity search RPC
 */
export interface SearchResult {
  id: number;
  content: string;
  source_file: string;
  heading_path: string | null;
  similarity: number;
}

/**
 * CLI options for the ingest command
 */
export interface IngestOptions {
  /** Path to documentation directory */
  docs: string;
  /** Version tag for this ingestion run */
  version: string;
  /** Preview mode - don't upload to database */
  dryRun: boolean;
}
```

Types are designed to:
- Match the database schema exactly (embedding is number[], not Float32Array)
- Be self-documenting with JSDoc comments
- Support the full pipeline from loading through upload
  </action>
  <verify>
File scripts/ingest/types.ts exists
Run `npx tsc --noEmit` (should succeed)
Contains exports for ChunkWithContext, ChunkMetadata, DocumentChunk
  </verify>
  <done>
All shared types are defined and TypeScript compiles. Other modules can import from ./types.ts.
  </done>
</task>

</tasks>

<verification>
After completing all tasks:
1. `npm install` succeeds
2. `npx tsc --noEmit` succeeds
3. `ls scripts/db/schema.sql` shows file exists
4. `ls scripts/ingest/types.ts` shows file exists
5. User should run schema.sql in Supabase SQL Editor (checkpoint in Plan 04)
</verification>

<success_criteria>
- package.json contains all 11 production dependencies from research
- tsconfig.json has strict mode enabled
- .env.example documents all required environment variables
- scripts/db/schema.sql contains complete pgvector setup
- scripts/ingest/types.ts exports all interfaces needed by other modules
- TypeScript compiles without errors
</success_criteria>

<output>
After completion, create `.planning/phases/01-data-pipeline/01-01-SUMMARY.md`
</output>
